# training 노트 정리

단계별 리스트 (순서도 형식)

1. 데이터 수집 
2. 데이터 라벨링 
   1. 데이터 전처리/증강 
3. 모델 선택/설계 
4. 모델 학습 
5. 모델 평가 
6. 결과에 따른 분기점
   - 결과 좋음 → 8. 모델 배포 
   - 결과 개선 필요 → 1. 데이터 수집으로 돌아가기
7. 모니터링/개선 🔄



### 1. 데이터 수집

데이터셋을 [kaggle](https://www.kaggle.com/datasets/tongpython/cat-and-dog) 사이트에서 cat과 dog의 사진 test_set과 training_set으로 (5000 X 2 X 2)장씩 수집하였습니다.



사진의 종류는 cat과 dog외에도 정말 많이 있을 것입니다.

다만 데이터 학습이 처음이어서 실습에 의의를 두고 일단 2가지 동물(cat, dog)만 학습시켜 서비스를 제작하였습니다.



이 과정을 통해 AI 학습 프로세스와 감을 익힌 뒤 더욱 다양한 사진을 분류할 수 있는 모델로 학습시킬 계획입니다.



### 2. 데이터 라벨링

아래의 디렉토리 구조로 이미지 데이터를 라벨링하였습니다.

```
picstory
 ├─training
 │  └─data_set
 │      ├─test_set
 │      │  ├─cat
 │      │  └─dog
 │      └─training_set
 │          ├─cat
 │          └─dog
 └─serving
```



### 3. 데이터 전처리 및 증강

`DataHandler` 객체를 생성하여 훈련 및 검증 데이터의 전처리와 증강 과정을 진행합니다.



**배치크기**

컴퓨팅 자원에 알맞게 배치 크기를 조정합니다. 배치 크기란 한번에 학습시킬 데이터 묶음을 의미합니다. 배치 크기가 클수록 한번에 많은 데이터를 처리하여 학습속도가 빨라지며, 그래디언트(경사)의 변동성이 작아져 학습이 더 안정적이게 됩니다. 

허나 메모리를 많이 사용하기에 메모리 부족 문제가 발생할 수 있습니다. 배치 크기는 학습 안정성, 학습 속도, 메모리 효율성 사이의 균형을 맞추어 적절하게 선택해야 합니다.



**워커 수**

컴퓨팅 자원에 알맞게 워커 수를 설정합니다. 워커는 디스크에 저장된 데이터를 모델이 이해할 수 있는 형태로 변환하고 전처리를 합니다. 워커 수가 많을수록 이 과정을 병렬로 처리하는 스레드가 많아지고, GPU가 지속적으로 데이터를 받아 학습할 수 있습니다. 

허나 CPU와 메모리 사용량이 크게 증가하여 오버헤드가 발생할 수 있습니다. 

워커 수가 0이면 디스크에서 데이터를 가져오기, 이미지 전처리, 메인 프로세스로 배치 크기 만큼의 데이터 전달하는 과정이 순차적으로 처리됩니다. 워커 수가 1 이상이면 여러 워커가 동시에 병렬로 작업하여 처리속도를 향상시킬 수 있습니다.  



**데이터 변환**

1. 모델이 이해할 수 있는 형태로 만들기

모델이 학습하기 위해서는 모든 입력 데이터가 동일한 형식이어야 합니다. 이미지를 동일한 크기로 맞추고, 픽셀값인 이미지를 PyTorch모델이 이해할 수 있는 텐서값으로 변환합니다. 또한 정규화를 통해 픽셀 값 평균을 0으로, 표준 편차를 1로 설정하여 더욱 안정적인 학습을 진행합니다.



2. 일반화 능력을 향상시키는 방법 (데이터 증강)

훈련 데이터를 무작위로 뒤집거나 자르는 등의 변형을 가합니다. 예를 들어, 고양이 이미지를 학습시킬 때, 원본 이미지만으로 학습하면 모델이 정면의 고양이만 인식할 수 있습니다. 하지만 이미지를 무작위로 뒤집거나 회전시키면, 모델은 고양이가 어떤 방향에 있든 인식할 수 있는 능력을 갖게 됩니다. 이는 모델이 다양한 상황에서도 객체를 인식하도록 도와 일반화 능력을 크게 향상시킵니다.



3. 검증 데이터 변환

검증 이미지의 정중앙을 224x224 크기로 잘라냅니다. 무작위로 자르는 것과 달리, 이 방법은 항상 같은 부분을 자르기 때문에 일관된 결과를 얻을 수 있습니다. 이로써 모델의 성능을 공정하게 평가할 수 있습니다.



### 4. 모델 선택 및 설계

이미지 분류 모델에는 From Scratch, Tansfer Learning 두 가지 방법이 있는데, 저는 초보자이므로 사전 학습 모델을 이용하는 Tansfer Learning로 진행하겠습니다.

이미지 분류에는 합성곱 신경망(CNN) 알고리즘을 사용하는데, VGG16 모델이 대표적인 한 예입니다. 이를 추가 학습시켜 사용할 것입니다.



`VGG16FineTuner` 객체를 생성하여 설계 과정을 진행합니다.



**모델 가져오기**

VGG16 모델과 미리 학습된 가중치를 불러옵니다. 특징 추출기 층의 모든 가중치를 업데이트 되지 않도록 설정합니다. 마지막 분류기 층만 2개의 클래스를 분류하도록 조정합니다. 손실함수, 옵티마이저를 설정합니다.



**학습 과정 설계**

한 번의 epoch 동안 모델을 학습시킵니다. 배치 묶음을 불러오며 연산하여 기울기를 조정하고 이를 바탕으로 가중치를 업데이트합니다. 구체적인 연산 이론은 심화 학습을 진행할 예정입니다.



**검증 과정 설계**

한 번의 epoch 동안 모델을 검증합니다. 배치 묶음을 불러오며 연산하여 손실과 정확도를 계산합니다. 이를 바탕으로 모델의 성능을 판단합니다. 구체적인 연산 이론은 심화 학습을 진행할 예정입니다.



**평과 과정 설계**

검증 과정과 기능이 일치합니다. 다만 검증은 훈련 과정 중에 사용되고, 평가는 최종 성능 평가에 사용되므로 구분하여 가독성을 높입니다. 새로운 데이터에 대한 예측 성능을 판단합니다.



### 5. 모델 학습

`Trainer` 객체를 생성하여 학습과정을 진행합니다.



**최고 성능 모델 저장**

지정된 횟수 epoch 만큼 모델을 반복하고 훈련 및 검증합니다. 앞서 설계한 `VGG16FineTuner` 객체의 학습 및 검증 메서드를 사용합니다. 이 때, epoch 마다 가장 정확도가 높은 단계의 가중치를 저장합니다.



---

최종적으로 train.py에서 앞선 과정들을 모두 수행합니다.



### 6. 모델 평가

test.py에서 새로운 데이터가 담긴 로더를 생성하고, `VGG16FineTuner`에 저장된 가중치를 로드하여 평가를 수행합니다. 



결과가 좋다면 모델 배포단계로 넘어가고, 나쁘다면 데이터 수집단계로 돌아갑니다.

